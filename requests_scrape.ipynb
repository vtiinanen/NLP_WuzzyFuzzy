{
 "cells": [
  {
   "cell_type": "code",
   "source": "import requests\ns = requests.Session()\ns.headers = {\n    #\"referer\" : \"http://www.google.com\",\n    \"user-agent\" : \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\"\n}\nfrom bs4 import BeautifulSoup\nimport re",
   "metadata": {
    "tags": [],
    "cell_id": "00001-1b7756db-de6e-4898-92ae-247dbeed502a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6bb3a49c",
    "execution_start": 1635093420835,
    "execution_millis": 133,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-cc31dd4a-c857-4abe-a0e1-f580ed0bf992",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "79147f8",
    "execution_start": 1635093421026,
    "execution_millis": 8686,
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\" Form Google search urls for scraping \"\"\"\n\nGOOGLE_ORIG_URL = 'https://www.google.com/search?q=carbon+footprint'\n\npage_amount = 11\nGOOGLE_URLS = [GOOGLE_ORIG_URL + '&start=' + str(i*10) for i in range(0, page_amount)]\nprint(GOOGLE_URLS)\n\n\"\"\" Scrape Google search results \"\"\"\n\ndef get_response(url):\n    resp = s.get(url)\n    if resp.status_code != 200:\n        print(resp.text)\n        raise\n    return resp\n\ngoogle_responses = [get_response(url) for url in GOOGLE_URLS]\nprint(google_responses)\n\n\"\"\" Parse scraped Google search results \"\"\"\n\ndef google_get_description(response):\n    returnable=[]\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for s in soup.find_all(\"div\", class_=\"g\"):\n        spans = s.find_all('span', class_=None)\n        without_attrs = [s for s in spans if (s.attrs == {})]\n        without_feedback = [s for s in without_attrs if 'Feedback' != s.text]\n        without_cached = [s for s in without_feedback if 'Cached' != s.text]\n        without_similar = [s for s in without_cached if 'Similar' != s.text]\n        without_cachedsimilar = [s for s in without_similar if 'CachedSimilar' != s.text]\n        for desc in without_cachedsimilar:\n            desc_text = desc.text\n            returnable.append(desc_text.replace('\\xa0', ' '))\n    return returnable\n\ngoogle_descriptions_of_pages = [google_get_description(res) for res in google_responses]\n\ndef flatten(t):\n    return [item for sublist in t for item in sublist]\n\nbs4_scraped_snippets = flatten(google_descriptions_of_pages)\n\nprint(*bs4_scraped_snippets[:15], sep='\\n')\nprint(len(bs4_scraped_snippets))\n# Possibly not usable data atm\n# Although it doesn't cost anything to calc the metrics for this data also\n\nwith open(\"google_requests_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bs4_scraped_snippets))",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "['https://www.google.com/search?q=carbon+footprint&start=0', 'https://www.google.com/search?q=carbon+footprint&start=10', 'https://www.google.com/search?q=carbon+footprint&start=20', 'https://www.google.com/search?q=carbon+footprint&start=30', 'https://www.google.com/search?q=carbon+footprint&start=40', 'https://www.google.com/search?q=carbon+footprint&start=50', 'https://www.google.com/search?q=carbon+footprint&start=60', 'https://www.google.com/search?q=carbon+footprint&start=70', 'https://www.google.com/search?q=carbon+footprint&start=80', 'https://www.google.com/search?q=carbon+footprint&start=90', 'https://www.google.com/search?q=carbon+footprint&start=100']\n[<Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>]\nA carbon footprint is the total amount of greenhouse gases (including carbon dioxide and methane) that are generated by our actions.\nLeading online carbon footprint calculation tools and information to help reduce and offset your emissions - for business and individuals.\nLeading online carbon footprint calculation tools and information to help reduce and offset your emissions - for business and individuals.\nA carbon footprint is the total greenhouse gas (GHG) emissions caused by an individual, event, organization, service, place or product, expressed as carbon ...\nThe carbon Footprint is currently 60 percent of humanity's overall Ecological Footprint and its most rapidly growing component. Humanity's carbon Footprint has ...\nMany of our daily activities - such as using electricity, driving a car, or disposing of waste - cause greenhouse gas emissions. Together these ...\nA carbon footprint is the total amount of greenhouse gas emissions that come from the production, use and end-of-life of a product or service.\n“A carbon footprint is the total greenhouse gas (GHG) emissions caused directly and indirectly by an individual, organization, event or product.\nWhat is your carbon footprint? Calculate it now. Offsetting the carbon emissions from your lifestyle is a critical step toward fighting climate change.\nA carbon footprint is the amount of greenhouse gases—primarily carbon dioxide—released into the atmosphere by a particular human activity.\nCarbon footprint\nA carbon footprint is the total greenhouse gas emissions caused by an individual, event, organization, service, place or product, expressed as carbon dioxide equivalent.\n Wikipedia\n \nUse the World's most popular online carbon footprint calculator, and it's FREE. Calculate your carbon emissions from Buildings, Cars, Flights and other ...\n117\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-5dd03146-f70d-4534-91c8-697501e38d03",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b726bcd2",
    "execution_start": 1635093429715,
    "execution_millis": 7113,
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\" BBC scrape \"\"\"\n\nBBC_ORIG_URL = 'https://www.bbc.co.uk/search?q=carbon+footprint'\n\npage_amount = 11\nBBC_URLS = [BBC_ORIG_URL + '&page=' + str(i) for i in range(1, page_amount)]\n#print(BBC_URLS)\n\nbbc_responses = [get_response(url) for url in BBC_URLS]\n\ndef get_bbc_heading(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    regex = re.compile('.*-Promo.')\n    for a in soup.find_all(\"a\", {\"class\" : regex}):\n        returnable.append(a.text)\n    return returnable\n\ndef get_bbc_description(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    regex = re.compile('.*-Paragraph.')\n    for p in soup.find_all(\"p\", {\"class\" : regex}):\n        if '© 2021 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.' in p.text:\n            continue\n        returnable.append(p.text)\n    return returnable\n\nbbc_headings_of_pages = [get_bbc_heading(res) for res in bbc_responses]\nbbc_scraped_headings = flatten(bbc_headings_of_pages)\nprint(*bbc_scraped_headings[:15], sep='\\n')\nprint(len(bbc_scraped_headings))\n\nwith open(\"bbc_requests_headings_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bbc_scraped_headings))\n\nprint('\\n-----\\n')\n\nbbc_descriptions_of_pages = [get_bbc_description(res) for res in bbc_responses]\nbbc_scraped_snippets = flatten(bbc_descriptions_of_pages)\nprint(*bbc_scraped_snippets[:15], sep='\\n')\nprint(len(bbc_scraped_snippets))\n\nwith open(\"bbc_requests_snippets_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bbc_scraped_snippets))",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Dani's House: Series 1: It's Not Easy Being Green\nHorizon: 2021: Feast to Save the Planet\nShop Well for the Planet?: Series 1: Episode 2\nClacton Airshow looks to reduce carbon footprint\nLandward: 2021: Episode 18\nCountryfile: Offa's Dyke Path\nRoyal Institution Christmas Lectures: 2020: Planet Earth - A User's Guide: Up in the Air\nHayley Goes...: Series 2: Back to Nature\nShop Well for the Planet?: Series 1: Episode 1\nNewcastle's plastic grass sparks 'carbon footprint' row\nClimate change: Could Welsh farms help meet targets?\nFirms want help to measure their carbon footprint\nDo consumers care about carbon footprint?\nCOP26: Climate change what do all the words mean?\nFarming Today: 19/08/21 - The carbon footprint of milk, Wheat harvest in Yorkshire\n100\n\n-----\n\nSam dares Dani and Toby to cut their carbon footprint.\nA dinner party where special guests are scored on the environmental impact of their meal.\nCan the gang get a whole family on board this eco and money-saving mission?\nThe Clacton Airshow is considering planting trees to offset emissions from next year's display.\nDougie and Nick are in Cullen in Moray cooking the famous local soup.\nMatt Baker and Ellie Harrison celebrate the 50th anniversary of Offa’s Dyke Path.\nDr Tara Shine takes a deep breath and explores the gases that make up the air we breath.\nCan presenter Hayley Pearce ditch her mod cons to embrace Mother Earth?\nCan the gang convince a family that it’s possible to go green and save some cash?\nEnvironmentalists say Newcastle's plastic grass has a \"huge carbon footprint\" and want it banned.\nAgriculture is a source of emissions, but a union says it can help to cut greenhouse gases.\nMany small businesses say they lack the resources needed to calculate their carbon footprint.\nCompanies are considering using carbon labelling the same way as they use nutrition information. Sam and Neil discuss the idea and teach you related vocabulary.\nCOP26 is right around the corner, so here is a handy guide to some of the key terms you'll be hearing throughout the big climate change conference.\nA new report says UK milk is produced with half of the global average carbon footprint.\n100\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "\"\"\" The Register scrape \"\"\"\n\nThe_Register_ORIG_URL = 'https://search.theregister.com/?q=carbon+footprint&results_per_page=10&sort=rel'\n\npage_amount = 11\nThe_Register_URLS = [The_Register_ORIG_URL + '&page=' + str(i) for i in range(1, page_amount)]\n\nthe_register_responses = [get_response(url) for url in The_Register_URLS]\n\ndef get_the_register_heading(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for article in soup.find_all(\"article\"):\n        for h4 in article.find_all(\"h4\"):\n            returnable.append(h4.text)\n    return returnable\n\ndef get_the_register_description(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for article in soup.find_all(\"article\"):\n        for div in article.find_all(\"div\", class_=\"standfirst\"):\n            returnable.append(div.text)\n    return returnable\n\nthe_register_headings_of_pages = [get_the_register_heading(res) for res in the_register_responses]\nthe_register_scraped_headings = flatten(the_register_headings_of_pages)\nprint(*the_register_scraped_headings[:15], sep='\\n')\nprint(len(the_register_scraped_headings))\n\nwith open(\"register_requests_headings_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(the_register_scraped_headings))\n\nprint('\\n-----\\n')\n\nthe_register_descriptions_of_pages = [get_the_register_description(res) for res in the_register_responses]\nthe_register_scraped_snippets = flatten(the_register_descriptions_of_pages)\nprint(*the_register_scraped_snippets[:15], sep='\\n')\nprint(len(the_register_scraped_snippets))\n\nwith open(\"register_requests_snippets_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(the_register_scraped_snippets))",
   "metadata": {
    "tags": [],
    "cell_id": "00002-5bacb946-b6a9-49dc-9086-bf3dfdd2a291",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "69431ebf",
    "execution_start": 1635093436825,
    "execution_millis": 1790,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Amazon: Our carbon footprint went up 19% last year but we grew even more than that, so 'carbon intensity' is down\nMeasuring your carbon footprint? There's no app for that\nAI me to the Moon... Carbon footprint for 'training GPT-3' same as driving to our natural satellite and back\nMicrosoft picks a side, aims to make the business 'carbon-negative' by 2030\nAzure Emissions Dashboard shows how you and Microsoft are slowly killing the planet with your cloud workloads\nGoogle Cloud will let you know how your workloads are damaging the environment\nJapan's NTT Group to allow remote work for all 320,000 staff\nAltered carbon: Boffins automate DNA storage with decent density – but lousy latency\nWipro wins $44.5m deal for data centres and managed services at UK's National Grid\n'Green' Apple: We've smudged a bit off our carbon footprint\nBrit MPs to Apple CEO: Please stop ignoring our questions about repairability and the environment\nBill Gates on climate change: Planting trees is not the answer, emissions need to be zeroed out to avoid disaster\nIt's one thing to have the world in your hands – what are you going to do with it?\nGoogle emits Chrome 94 with 'Idle Detection' API to detect user inactivity amid opposition\nAI caramba, those neural networks are power-hungry: Counting the environmental cost of artificial intelligence\n100\n\n-----\n\nAlrighty... that's OK then?\nColumn Smartphones can keep us informed about everything other than environmental impact. That needs to change\nGet ready for Energy Star stickers on your robo-butlers, maybe?\nPlans to cancel out emissions from power consumption since 1975. No word on warming through excessive corporate hot air though\nHere's an even cheerier thought – it requires a Power BI Pro subscription\nGoogle Cloud Next '21 brings Distributed Edge, emissions metrics, and a Cybersecurity Action Team\nDitching central offices in favour of over 250 regional facilities for a workforce twice the size of Microsoft's\nAn entire data centre the size of a sugar cube? Sweet!\nIndian outsourcer bags another utility\nEr, you're still manufacturing computers, right?\niGiant needs to take accountability for society's throwaway culture, claims select committee\nReview 'Every country will need to change its ways' says Microsoft billionaire\nColumn Google won the patent battle against ART+COM, but we were left with little more than a toy\nMozilla, Apple register dismay as worries surface over privacy, potential crypto mining behind user's back\nFeature (And, also worryingly, its increasing financial cost)\n100\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=df8df42c-8503-4bb3-8c9d-497cf36bf82c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "7109f5aa-1305-4982-8cb4-21bcda754f45",
  "deepnote_execution_queue": []
 }
}