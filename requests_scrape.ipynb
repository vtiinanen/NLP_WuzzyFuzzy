{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-1b7756db-de6e-4898-92ae-247dbeed502a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "99b4fdb2",
    "execution_start": 1635606278762,
    "execution_millis": 316,
    "deepnote_cell_type": "code"
   },
   "source": "import requests\ns = requests.Session()\ns.headers = {\n    #\"referer\" : \"http://www.google.com\",\n    \"user-agent\" : \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\"\n}\nfrom bs4 import BeautifulSoup\nimport re\n\ndef backup_html(title, responses):\n    for idx, response in enumerate(responses):\n        with open(f\"original_responses/{title}_response_{idx}\", \"w\") as s_file:\n            soup = BeautifulSoup(response.content, \"html.parser\")\n            s_file.write(soup.prettify())",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-cc31dd4a-c857-4abe-a0e1-f580ed0bf992",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1c09b7fa",
    "execution_start": 1635606279078,
    "execution_millis": 9889,
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\" Form Google search urls for scraping \"\"\"\n\nGOOGLE_ORIG_URL = 'https://www.google.com/search?q=carbon+footprint'\n\npage_amount = 11\nGOOGLE_URLS = [GOOGLE_ORIG_URL + '&start=' + str(i*10) for i in range(0, page_amount)]\nprint(GOOGLE_URLS)\n\n\"\"\" Scrape Google search results \"\"\"\n\ndef get_response(url):\n    resp = s.get(url)\n    if resp.status_code != 200:\n        print(resp.text)\n        raise\n    return resp\n\ngoogle_responses = [get_response(url) for url in GOOGLE_URLS]\nprint(google_responses)\nbackup_html('google', google_responses)\n\n\"\"\" Parse scraped Google search results \"\"\"\n\ndef google_get_heading(response):\n    returnable=[]\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for h3 in soup.select(\"div > div > div > a > h3\"):\n        h3_text = h3.text\n        returnable.append(h3_text.replace('\\xa0', ' '))\n    return returnable\n\ndef google_get_description(response):\n    returnable=[]\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for s in soup.find_all(\"div\", class_=\"g\"):\n        spans = s.find_all('span', class_=None)\n        without_attrs = [s for s in spans if (s.attrs == {})]\n        without_feedback = [s for s in without_attrs if 'Feedback' != s.text]\n        without_cached = [s for s in without_feedback if 'Cached' != s.text]\n        without_similar = [s for s in without_cached if 'Similar' != s.text]\n        without_cachedsimilar = [s for s in without_similar if 'CachedSimilar' != s.text]\n        for desc in without_cachedsimilar:\n            desc_text = desc.text\n            returnable.append(desc_text.replace('\\xa0', ' '))\n    return returnable\n\ndef flatten(t):\n    return [item for sublist in t for item in sublist]\n\ngoogle_headings_of_pages = [google_get_heading(res) for res in google_responses]\nbs4_scraped_headings = flatten(google_headings_of_pages)\nprint(*bs4_scraped_headings[:15], sep='\\n')\nprint(len(bs4_scraped_headings))\n\nwith open(\"google_requests_headings_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bs4_scraped_headings))\n\nprint('\\n-----\\n')\n\ngoogle_descriptions_of_pages = [google_get_description(res) for res in google_responses]\nbs4_scraped_descriptions = flatten(google_descriptions_of_pages)\nprint(*bs4_scraped_descriptions[:15], sep='\\n')\nprint(len(bs4_scraped_descriptions))\n\nwith open(\"google_requests_descriptions_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bs4_scraped_descriptions))",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "['https://www.google.com/search?q=carbon+footprint&start=0', 'https://www.google.com/search?q=carbon+footprint&start=10', 'https://www.google.com/search?q=carbon+footprint&start=20', 'https://www.google.com/search?q=carbon+footprint&start=30', 'https://www.google.com/search?q=carbon+footprint&start=40', 'https://www.google.com/search?q=carbon+footprint&start=50', 'https://www.google.com/search?q=carbon+footprint&start=60', 'https://www.google.com/search?q=carbon+footprint&start=70', 'https://www.google.com/search?q=carbon+footprint&start=80', 'https://www.google.com/search?q=carbon+footprint&start=90', 'https://www.google.com/search?q=carbon+footprint&start=100']\n[<Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>, <Response [200]>]\nCalculate Your Carbon Footprint - The Nature Conservancy\ncarbonfootprint.com - Home of Carbon Footprinting\nCarbon footprint - Wikipedia\nCarbon Footprint Calculator | Climate Change | US EPA\nHow to Reduce Your Carbon Footprint\nClimate Change & the Carbon Footprint\nCarbon Footprint Factsheet | Center for Sustainable Systems\nCarbon Footprint Calculator - Conservation International\nWhat is a Carbon Footprint? How Do You Calculate ... - TakePart\nCarbon Footprint Calculator\nCarbon Footprint Definition - Youmatter\ncarbon footprint | Definition, Examples, Calculation, Effects ...\nCarbon Footprint - Amazon Sustainability\n25+ Tips to Reduce Carbon Footprint from COTAP.org\nCarbon footprinting guide\n108\n\n-----\n\nA carbon footprint is the total amount of greenhouse gases (including carbon dioxide and methane) that are generated by our actions.\nLeading online carbon footprint calculation tools and information to help reduce and offset your emissions - for business and individuals.\nLeading online carbon footprint calculation tools and information to help reduce and offset your emissions - for business and individuals.\nA carbon footprint is the total greenhouse gas (GHG) emissions caused by an individual, event, organization, service, place or product, expressed as carbon ...\nThe calculator estimates your footprint in three areas: home energy, transportation and waste. Everyone's carbon footprint is different ...\nA carbon footprint is the total amount of greenhouse gas emissions that come from the production, use and end-of-life of a product or service.\nToday, the term “carbon footprint” is often used as shorthand for the amount of carbon (usually in tonnes) being emitted by an activity or organization. The ...\n“A carbon footprint is the total greenhouse gas (GHG) emissions caused directly and indirectly by an individual, organization, event or product.\nWhat is your carbon footprint? Calculate it now. Offsetting the carbon emissions from your lifestyle is a critical step toward fighting climate change.\nA carbon footprint is the amount of greenhouse gases—primarily carbon dioxide—released into the atmosphere by a particular human activity.\nUse the World's most popular online carbon footprint calculator, and it's FREE. Calculate your carbon emissions from Buildings, Cars, Flights and other ...\nAccording to WHO, a carbon footprint is a measure of the impact your activities have on the amount of carbon dioxide (CO2) produced through the ...\nCarbon footprint, amount of carbon dioxide emissions associated with all the activities of a person or other entity. It includes direct emissions, ...\nAmazon's corporate carbon footprint quantifies the total greenhouse gas emissions attributed to our direct and indirect operational activities.\nReduce carbon footprint with these handy tips. Calculate your emissions & buy offsets that change lives in regions where incomes are less than $2/day.\n112\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-5dd03146-f70d-4534-91c8-697501e38d03",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f33fd8de",
    "execution_start": 1635606288984,
    "execution_millis": 5161,
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\" BBC scrape \"\"\"\n\nBBC_ORIG_URL = 'https://www.bbc.co.uk/search?q=carbon+footprint'\n\npage_amount = 11\nBBC_URLS = [BBC_ORIG_URL + '&page=' + str(i) for i in range(1, page_amount)]\n#print(BBC_URLS)\n\nbbc_responses = [get_response(url) for url in BBC_URLS]\nbackup_html('bbc', bbc_responses)\n\ndef get_bbc_heading(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    regex = re.compile('.*-Promo.')\n    for a in soup.find_all(\"a\", {\"class\" : regex}):\n        returnable.append(a.text)\n    return returnable\n\ndef get_bbc_description(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    regex = re.compile('.*-Paragraph.')\n    for p in soup.find_all(\"p\", {\"class\" : regex}):\n        if '© 2021 BBC. The BBC is not responsible for the content of external sites. Read about our approach to external linking.' in p.text:\n            continue\n        returnable.append(p.text)\n    return returnable\n\nbbc_headings_of_pages = [get_bbc_heading(res) for res in bbc_responses]\nbbc_scraped_headings = flatten(bbc_headings_of_pages)\nprint(*bbc_scraped_headings[:15], sep='\\n')\nprint(len(bbc_scraped_headings))\n\nwith open(\"bbc_requests_headings_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bbc_scraped_headings))\n\nprint('\\n-----\\n')\n\nbbc_descriptions_of_pages = [get_bbc_description(res) for res in bbc_responses]\nbbc_scraped_descriptions = flatten(bbc_descriptions_of_pages)\nprint(*bbc_scraped_descriptions[:15], sep='\\n')\nprint(len(bbc_scraped_descriptions))\n\nwith open(\"bbc_requests_descriptions_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(bbc_scraped_descriptions))",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "Planet Norfolk: Reducing the carbon footprint of milk\nLife Hacks - How to Save the Planet: How to reduce our digital carbon footprint\nClimate change: Four things you can do about your carbon footprint\nClimate change: How can I reduce my carbon footprint?\nDani's House: Series 1: It's Not Easy Being Green\nHorizon: 2021: Feast to Save the Planet\nShop Well for the Planet?: Series 1: Episode 2\nManchester Airport first to get direct supply of sustainable jet fuel\nLandward: 2021: Episode 18\nCountryfile: Offa's Dyke Path\nRoyal Institution Christmas Lectures: 2020: Planet Earth - A User's Guide: Up in the Air\nShop Well for the Planet?: Series 1: Episode 3\nClacton Airshow looks to reduce carbon footprint\nHayley Goes...: Series 2: Back to Nature\nThe Lynette Fay Show: Deliciously Ella in Conversation\n100\n\n-----\n\nTim Addicott finds out how Norfolk's making changes to tackle climate change's effects.\nVick and Katie discuss our digital carbon footprint with Hendrikus van Hensbergen.\nSmall changes to our lifestyles and choices could limit our personal carbon footprint.\nPublic figures in Wales tell us what they are doing differently to combat climate change.\nSam dares Dani and Toby to cut their carbon footprint.\nA dinner party where special guests are scored on the environmental impact of their meal.\nCan the gang get a whole family on board this eco and money-saving mission?\nThe sustainable fuel is blended with traditional jet fuel, with a 70% lower carbon footprint.\nDougie and Nick are in Cullen in Moray cooking the famous local soup.\nMatt Baker and Ellie Harrison celebrate the 50th anniversary of Offa’s Dyke Path.\nDr Tara Shine takes a deep breath and explores the gases that make up the air we breath.\nCan a family be convinced that going greener doesn’t have to cost more or be a hassle?\nThe Clacton Airshow is considering planting trees to offset emissions from next year's display.\nCan presenter Hayley Pearce ditch her mod cons to embrace Mother Earth?\nElla Mills from Deliciously Ella on a plant-based diet; foraging for ingredients locally\n100\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-5bacb946-b6a9-49dc-9086-bf3dfdd2a291",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ada22a7f",
    "execution_start": 1635606294166,
    "execution_millis": 2308,
    "deepnote_cell_type": "code"
   },
   "source": "\"\"\" The Register scrape \"\"\"\n\nThe_Register_ORIG_URL = 'https://search.theregister.com/?q=carbon+footprint&results_per_page=10&sort=rel'\n\npage_amount = 11\nThe_Register_URLS = [The_Register_ORIG_URL + '&page=' + str(i) for i in range(1, page_amount)]\n\nthe_register_responses = [get_response(url) for url in The_Register_URLS]\nbackup_html('the_register', the_register_responses)\n\ndef get_the_register_heading(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for article in soup.find_all(\"article\"):\n        for h4 in article.find_all(\"h4\"):\n            returnable.append(h4.text)\n    return returnable\n\ndef get_the_register_description(response):\n    returnable = []\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for article in soup.find_all(\"article\"):\n        for div in article.find_all(\"div\", class_=\"standfirst\"):\n            returnable.append(div.text)\n    return returnable\n\nthe_register_headings_of_pages = [get_the_register_heading(res) for res in the_register_responses]\nthe_register_scraped_headings = flatten(the_register_headings_of_pages)\nprint(*the_register_scraped_headings[:15], sep='\\n')\nprint(len(the_register_scraped_headings))\n\nwith open(\"register_requests_headings_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(the_register_scraped_headings))\n\nprint('\\n-----\\n')\n\nthe_register_descriptions_of_pages = [get_the_register_description(res) for res in the_register_responses]\nthe_register_scraped_descriptions = flatten(the_register_descriptions_of_pages)\nprint(*the_register_scraped_descriptions[:15], sep='\\n')\nprint(len(the_register_scraped_descriptions))\n\nwith open(\"register_requests_descriptions_scrape.csv\", \"w\") as s_file:\n    s_file.write(\"\\n\".join(the_register_scraped_descriptions))",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Amazon: Our carbon footprint went up 19% last year but we grew even more than that, so 'carbon intensity' is down\nMeasuring your carbon footprint? There's no app for that\nAI me to the Moon... Carbon footprint for 'training GPT-3' same as driving to our natural satellite and back\nMicrosoft picks a side, aims to make the business 'carbon-negative' by 2030\nAzure Emissions Dashboard shows how you and Microsoft are slowly killing the planet with your cloud workloads\nGoogle Cloud will let you know how your workloads are damaging the environment\nJapan's NTT Group to allow remote work for all 320,000 staff\nProduct release cycles are killing the environment, techies tell British Computer Society\nAltered carbon: Boffins automate DNA storage with decent density – but lousy latency\nWipro wins $44.5m deal for data centres and managed services at UK's National Grid\n'Green' Apple: We've smudged a bit off our carbon footprint\nBrit MPs to Apple CEO: Please stop ignoring our questions about repairability and the environment\nBill Gates on climate change: Planting trees is not the answer, emissions need to be zeroed out to avoid disaster\nIt's one thing to have the world in your hands – what are you going to do with it?\nGoogle emits Chrome 94 with 'Idle Detection' API to detect user inactivity amid opposition\n100\n\n-----\n\nAlrighty... that's OK then?\nColumn Smartphones can keep us informed about everything other than environmental impact. That needs to change\nGet ready for Energy Star stickers on your robo-butlers, maybe?\nPlans to cancel out emissions from power consumption since 1975. No word on warming through excessive corporate hot air though\nHere's an even cheerier thought – it requires a Power BI Pro subscription\nGoogle Cloud Next '21 brings Distributed Edge, emissions metrics, and a Cybersecurity Action Team\nDitching central offices in favour of over 250 regional facilities for a workforce twice the size of Microsoft's\nRunning Linux on a vintage box is one answer, but someone has to hold big tech's feet to fire\nAn entire data centre the size of a sugar cube? Sweet!\nIndian outsourcer bags another utility\nEr, you're still manufacturing computers, right?\niGiant needs to take accountability for society's throwaway culture, claims select committee\nReview 'Every country will need to change its ways' says Microsoft billionaire\nColumn Google won the patent battle against ART+COM, but we were left with little more than a toy\nMozilla, Apple register dismay as worries surface over privacy, potential crypto mining behind user's back\n100\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=df8df42c-8503-4bb3-8c9d-497cf36bf82c' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "7109f5aa-1305-4982-8cb4-21bcda754f45",
  "deepnote_execution_queue": []
 }
}